#!/usr/bin/env bash
# 
# gfw_whitelist2domains -- Extract domains from gfw_whitelist pac file
# 
# Error codes
ERR_REQUIRED_PROGRAM_NOT_FOUND=1
ERR_DOWNLOAD_PAC_FAILED=2
ERR_EXTRACT_DOMAINS_FAILED=3

# Requirements
programs=(curl awk sort uniq)
for p in ${programs[@]}; do
	type -a "$p" >/dev/null 2>&1  
	[[ $? -ne 0 ]] && {
		printf "Cannot find the required program. Please run this program with \"%s\" installed.\n" "$p" >&2
		exit "$ERR_REQUIRED_PROGRAM_NOT_FOUND"
	}
done

# Download gfw_whitelist pac file (Thanks nowall!)
pac_url='https://raw.githubusercontent.com/n0wa11/gfw_whitelist/master/whitelist.pac'
printf "Downloading gfw_whitelist pac file: %s..." "${pac_url}" >&2
pac="$(curl -so - whitelist.pac "${pac_url}")"
[[ $? -ne 0 ]] && {
	printf "failed!\n" >&2
	printf "Download gfw_whitelist pac file failed. Please check your network connection.\n" >&2
	exit "$ERR_DOWNLOAD_PAC_FAILED"
}
printf "OK\n" >&2

# Extract domains from gfw_whitelist pac file
printf "Extracting domains from gfw_whitelist pac file...\n" >&2
awk '$1 == "[", $1 ~ "],?" {if ($1 !~ /^\/\// && $1 != "[" && $1 !~ /],?/) print}' <<<"$pac" |awk -F\" '{if ($2 != ".wikipedia.org" && $2 != ".wsj.com" && $2 != ".google-analytics.com") print $2}' |sort |uniq 
[[ $? -ne 0 ]] && {
	printf "Extracting domains from gfw_whitelist pac file failed.\n" >&2
	exit "$ERR_EXTRACT_DOMAINS_FAILED"
}
printf "Extracting domains from gfw_whitelist pac file sucessfully.\n" >&2
